# AI Voice Assistant Configuration
# Optimized for RTX 3050 6GB VRAM

# Models Configuration
models:
  # STT Model (Local Whisper) - Optimized for RTX 3050 6GB VRAM
  stt:
    model_name: "kyutai/stt-1b-en_fr-trfs"
    device: "cuda"
    
  # LLM Model (Your existing Ollama)
  llm:
    base_url: "http://localhost:11434"
    model_name: "gemma3:1b"  # Using 1B model for optimal VRAM usage (was 4b)
    # Alternative: "mistral:latest" if you want to try your other model
    
  # TTS Model
  tts:
    primary: "kokoro"  # Use high-quality TTS
    device: "cuda"     # Use GPU for performance
    fallback: "espeak" # Fallback if Kokoro fails
    
  # Vision Model (Same as conversation for simplicity)
  vision:
    base_url: "http://localhost:11434" 
    model_name: "gemma3:1b"

# Audio Configuration  
audio:
  sample_rate: 16000
  channels: 1
  
# Voice Recording Configuration (Turn-based)
voice_recording:
  # Timing configuration for turn-based conversation
  tts_buffer_before_recording: 1.0    # Wait 1s after TTS finishes before enabling mic
  recording_duration: 12.0            # Record user for 12 seconds max
  warning_countdown_start: 5.0        # Start "recording will stop" countdown at 5s remaining
  processing_timeout: 30.0            # Max time to wait for STT+LLM+TTS processing
  
  # Audio quality settings
  echo_cancellation: true
  noise_suppression: true
  auto_gain_control: true
  
# Performance Configuration
performance:
  max_vram_gb: 5.0  # Leave 2GB buffer on 6GB card
  enable_torch_compile: false  # Disable for compatibility
  
# Server Configuration
server:
  host: "0.0.0.0"
  port: 8080
  debug: true